{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8346cd73-6334-42e9-9ff0-7d49d9ce674e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, log_loss, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "811c98c3-6ac3-4e37-ab68-a0096fa8bc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# NOTE: this notebook assumes the brain tumor data is in a directory at the root\n",
    "# of this repository called 'BrainTumorData'.\n",
    "#\n",
    "# To make this work:\n",
    "# 1 - go to https://www.kaggle.com/datasets/sartajbhuvaji/brain-tumor-classification-mri\n",
    "# 2 - download the .zip file to this directory\n",
    "# 3 - unzip the archive\n",
    "# 4 - rename the expanded directory to BrainTumorData\n",
    "\n",
    "\n",
    "data_directory = os.path.join(os.getcwd(), 'BrainTumorData')\n",
    "train_dir = os.path.join(data_directory, 'Training')\n",
    "test_dir = os.path.join(data_directory, 'Testing')\n",
    "\n",
    "train_imgs = []\n",
    "train_labels = []\n",
    "\n",
    "test_imgs = []\n",
    "test_labels = []\n",
    "\n",
    "\n",
    "# get labels from the file structure\n",
    "for label in os.listdir(train_dir):\n",
    "    for img in os.listdir(os.path.join(train_dir, label)):\n",
    "        train_imgs.append (img) \n",
    "        train_labels.append(label)\n",
    "        \n",
    "for label in os.listdir(train_dir):\n",
    "    for img in os.listdir(os.path.join(train_dir, label)):\n",
    "        train_imgs.append (img) \n",
    "        train_labels.append(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "039ae1a4-2521-4016-8c2d-28943546f888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloaders only support tensors, np arrays, lists, dicts, and numbers\n",
    "# define this function to cast PIL images to tensors\n",
    "transform_fn = transforms.Compose([\n",
    "    transforms.Resize((150,150)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),  \n",
    "    transforms.Normalize([0.5,0.5,0.5], \n",
    "                        [0.5,0.5,0.5])\n",
    "])\n",
    "\n",
    "# create a validation set from the test sset\n",
    "x_train, x_val, y_train, y_val = train_test_split(np.array(train_imgs), np.array(train_labels), test_size=0.1)\n",
    "\n",
    "# create dataloaders\n",
    "train_loader=DataLoader(\n",
    "    torchvision.datasets.ImageFolder(train_dir, transform=transform_fn),\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    ")\n",
    "test_loader=DataLoader(\n",
    "    torchvision.datasets.ImageFolder(test_dir, transform=transform_fn),\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "55ff844f-27f8-4cbe-b2f7-8aecaf47283a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get class names\n",
    "class_names = [label for label in os.listdir(train_dir)]\n",
    "\n",
    "# support GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "69a3abc6-4281-4413-81b5-737a8b0a2faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model and send it to the device\n",
    "model = models.resnet18().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a024c5ce-020e-4dbd-8990-07a51e481fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some deep learning overhead to help the model learn better\n",
    "# can tweak these if you want but don't need to\n",
    "warmup_steps = 5000 # delays using learning rate\n",
    "num_epochs = 10 # arbitrary for now\n",
    "learning_rate = 5e-3 # intial LR used after warmup\n",
    "weight_decay = 0.0 # throttles optimizer -- 0 for now\n",
    "\n",
    "num_update_steps_per_epoch = len(train_loader)\n",
    "max_train_steps = num_epochs * num_update_steps_per_epoch\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(), lr=learning_rate, weight_decay=weight_decay,\n",
    ")\n",
    "\n",
    "lr_scheduler = transformers.get_scheduler(\n",
    "    name='linear',\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=warmup_steps,\n",
    "    num_training_steps=max_train_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e560406-1e1e-4b38-b197-7d5861ef62b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, device):\n",
    "    # set the model to evaluation mode\n",
    "    model.eval()\n",
    "    for batch in tqdm(dataloader, desc=\"Evaluation\"):\n",
    "        # do some math\n",
    "        # return some numbers\n",
    "        pass\n",
    "        # Mike TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "95fd1b88-b41a-461d-902b-48f9cb981aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs...:   0%|                                                                                                                                                    | 0/10 [00:00<?, ?it/s]\n",
      "batches:   0%|                                                                                                                                                      | 0/45 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.0976, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "batches:   2%|███▏                                                                                                                                          | 1/45 [00:05<04:09,  5.66s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.0643, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "batches:   4%|██████▎                                                                                                                                       | 2/45 [00:10<03:50,  5.36s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.0665, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "batches:   7%|█████████▍                                                                                                                                    | 3/45 [00:16<03:42,  5.29s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.0307, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "batches:   9%|████████████▌                                                                                                                                 | 4/45 [00:21<03:37,  5.32s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.8890, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "batches:  11%|███████████████▊                                                                                                                              | 5/45 [00:26<03:33,  5.34s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.9116, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "batches:  13%|██████████████████▉                                                                                                                           | 6/45 [00:31<03:26,  5.29s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.9605, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "batches:  16%|██████████████████████                                                                                                                        | 7/45 [00:37<03:19,  5.25s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.8722, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "batches:  18%|█████████████████████████▏                                                                                                                    | 8/45 [00:42<03:13,  5.24s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.7804, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "batches:  20%|████████████████████████████▍                                                                                                                 | 9/45 [00:47<03:08,  5.25s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.8737, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "batches:  22%|███████████████████████████████▎                                                                                                             | 10/45 [00:52<03:04,  5.26s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.6826, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "batches:  24%|██████████████████████████████████▍                                                                                                          | 11/45 [00:58<03:02,  5.37s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.7489, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "batches:  27%|█████████████████████████████████████▌                                                                                                       | 12/45 [01:04<03:01,  5.49s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.4059, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "batches:  29%|████████████████████████████████████████▋                                                                                                    | 13/45 [01:09<02:53,  5.43s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.2750, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "batches:  31%|███████████████████████████████████████████▊                                                                                                 | 14/45 [01:14<02:47,  5.42s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.3792, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "batches:  33%|███████████████████████████████████████████████                                                                                              | 15/45 [01:20<02:48,  5.60s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.2911, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "batches:  36%|██████████████████████████████████████████████████▏                                                                                          | 16/45 [01:26<02:41,  5.57s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.2698, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "batches:  38%|█████████████████████████████████████████████████████▎                                                                                       | 17/45 [01:32<02:36,  5.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.2802, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "batches:  40%|████████████████████████████████████████████████████████▍                                                                                    | 18/45 [01:37<02:28,  5.51s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.8371, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "batches:  42%|███████████████████████████████████████████████████████████▌                                                                                 | 19/45 [01:42<02:21,  5.45s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.2512, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "batches:  44%|██████████████████████████████████████████████████████████████▋                                                                              | 20/45 [01:48<02:15,  5.42s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.1932, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "batches:  47%|█████████████████████████████████████████████████████████████████▊                                                                           | 21/45 [01:53<02:08,  5.36s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.8592, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "batches:  49%|████████████████████████████████████████████████████████████████████▉                                                                        | 22/45 [01:58<02:03,  5.39s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.8625, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "batches:  51%|████████████████████████████████████████████████████████████████████████                                                                     | 23/45 [02:04<02:00,  5.47s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.6643, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batches:  51%|████████████████████████████████████████████████████████████████████████                                                                     | 23/45 [02:10<02:04,  5.66s/it]\n",
      "epochs...:   0%|                                                                                                                                                    | 0/10 [02:10<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [91]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(preds,labels)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(loss)\n\u001b[0;32m---> 16\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     18\u001b[0m lr_scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/virtualenvs/health_medicine/lib/python3.9/site-packages/torch/_tensor.py:307\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    300\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    301\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    305\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    306\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 307\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/virtualenvs/health_medicine/lib/python3.9/site-packages/torch/autograd/__init__.py:154\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    152\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m--> 154\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "\n",
    "for epoch in tqdm(range(num_epochs), desc='training epochs'):\n",
    "    # set the model to train mode\n",
    "    model.train()\n",
    "    \n",
    "    for images, labels in tqdm(train_loader, desc='train batches'):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "                \n",
    "        preds = model(images).to(device)\n",
    "        \n",
    "        loss = F.cross_entropy(preds,labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "    # evaluate at the end of each epoch\n",
    "    # Mike TODO\n",
    "\n",
    "\n",
    "# save the model checkpoint after training\n",
    "# in case we want to use it again for class demo\n",
    "output_dir = 'output'\n",
    "try:\n",
    "    os.mkdir(output_dir)\n",
    "except:\n",
    "    # we don't care if it already exists... move on\n",
    "    pass\n",
    "\n",
    "model.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6f1681-896c-4ec1-8f1c-f8ee208384a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "health_medicine",
   "language": "python",
   "name": "health_medicine"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
