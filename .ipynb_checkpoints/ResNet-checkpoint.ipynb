{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8346cd73-6334-42e9-9ff0-7d49d9ce674e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, log_loss, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import transformers\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "811c98c3-6ac3-4e37-ab68-a0096fa8bc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# NOTE: this notebook assumes the brain tumor data is in a directory at the root\n",
    "# of this repository called 'BrainTumorData'.\n",
    "#\n",
    "# To make this work:\n",
    "# 1 - go to https://www.kaggle.com/datasets/sartajbhuvaji/brain-tumor-classification-mri\n",
    "# 2 - download the .zip file to this directory\n",
    "# 3 - unzip the archive\n",
    "# 4 - rename the expanded directory to BrainTumorData\n",
    "\n",
    "\n",
    "data_directory = os.path.join(os.getcwd(), 'BrainTumorData')\n",
    "train_dir = os.path.join(data_directory, 'Training')\n",
    "test_dir = os.path.join(data_directory, 'Testing')\n",
    "\n",
    "train_imgs = []\n",
    "train_labels = []\n",
    "\n",
    "test_imgs = []\n",
    "test_labels = []\n",
    "\n",
    "\n",
    "# get labels from the file structure\n",
    "for label in os.listdir(train_dir):\n",
    "    for img in os.listdir(os.path.join(train_dir, label)):\n",
    "        train_imgs.append (img) \n",
    "        train_labels.append(label)\n",
    "        \n",
    "for label in os.listdir(train_dir):\n",
    "    for img in os.listdir(os.path.join(train_dir, label)):\n",
    "        train_imgs.append (img) \n",
    "        train_labels.append(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "039ae1a4-2521-4016-8c2d-28943546f888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloaders only support tensors, np arrays, lists, dicts, and numbers\n",
    "# define this function to cast PIL images to tensors\n",
    "transform_fn = transforms.Compose([\n",
    "    transforms.Resize((150,150)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),  \n",
    "    transforms.Normalize([0.5,0.5,0.5], \n",
    "                        [0.5,0.5,0.5])\n",
    "])\n",
    "\n",
    "# create a validation set from the test sset\n",
    "x_train, x_val, y_train, y_val = train_test_split(np.array(train_imgs), np.array(train_labels), test_size=0.1)\n",
    "\n",
    "# create dataloaders\n",
    "train_loader=DataLoader(\n",
    "    torchvision.datasets.ImageFolder(train_dir, transform=transform_fn),\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    ")\n",
    "test_loader=DataLoader(\n",
    "    torchvision.datasets.ImageFolder(test_dir, transform=transform_fn),\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55ff844f-27f8-4cbe-b2f7-8aecaf47283a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get class names\n",
    "class_names = [label for label in os.listdir(train_dir)]\n",
    "\n",
    "# support GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69a3abc6-4281-4413-81b5-737a8b0a2faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model and send it to the device\n",
    "model = models.resnet18().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a024c5ce-020e-4dbd-8990-07a51e481fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some deep learning overhead to help the model learn better\n",
    "# can tweak these if you want but don't need to\n",
    "warmup_steps = 5000 # delays using learning rate\n",
    "num_epochs = 10 # arbitrary for now\n",
    "learning_rate = 5e-3 # intial LR used after warmup\n",
    "weight_decay = 0.0 # throttles optimizer -- 0 for now\n",
    "\n",
    "num_update_steps_per_epoch = len(train_loader)\n",
    "max_train_steps = num_epochs * num_update_steps_per_epoch\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(), lr=learning_rate, weight_decay=weight_decay,\n",
    ")\n",
    "\n",
    "lr_scheduler = transformers.get_scheduler(\n",
    "    name='linear',\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=warmup_steps,\n",
    "    num_training_steps=max_train_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e560406-1e1e-4b38-b197-7d5861ef62b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(predicted, labels):\n",
    "    batch_len, correct = 0, 0\n",
    "    batch_len = labels.size(0)\n",
    "    correct = (predicted == labels).sum().item()\n",
    "    return batch_len, correct\n",
    "\n",
    "def evaluate_model(model, test_loader):\n",
    "    # set the model to evaluation mode\n",
    "    losses = 0\n",
    "    num_samples_total = 0\n",
    "    correct_total = 0\n",
    "    model.eval()\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        out = model(inputs)\n",
    "        _, predicted = torch.max(out, 1)\n",
    "        loss = criterion(out, labels)\n",
    "        losses += loss.item()\n",
    "        b_len, corr = get_accuracy(predicted, labels)\n",
    "        num_samples_total += b_len\n",
    "        correct_total += corr\n",
    "        \n",
    "    accuracy = correct_total / num_samples_total\n",
    "    losses = losses / len(test_loader)\n",
    "    return accuracy, losses\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95fd1b88-b41a-461d-902b-48f9cb981aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epochs:   0%|          | 0/10 [00:00<?, ?it/s]\n",
      "train batches:   0%|          | 0/45 [00:00<?, ?it/s]\u001b[A\n",
      "train batches:   2%|▏         | 1/45 [00:03<02:51,  3.91s/it]\u001b[A\n",
      "train batches:   4%|▍         | 2/45 [00:07<02:48,  3.92s/it]\u001b[A\n",
      "train batches:   7%|▋         | 3/45 [00:12<02:58,  4.26s/it]\u001b[A\n",
      "train batches:   9%|▉         | 4/45 [00:17<03:08,  4.61s/it]\u001b[A\n",
      "train batches:  11%|█         | 5/45 [00:21<02:59,  4.49s/it]\u001b[A\n",
      "train batches:  13%|█▎        | 6/45 [00:25<02:48,  4.33s/it]\u001b[A\n",
      "train batches:  16%|█▌        | 7/45 [00:30<02:41,  4.25s/it]\u001b[A\n",
      "train batches:  18%|█▊        | 8/45 [00:34<02:38,  4.29s/it]\u001b[A\n",
      "train batches:  20%|██        | 9/45 [00:38<02:31,  4.20s/it]\u001b[A\n",
      "train batches:  22%|██▏       | 10/45 [00:42<02:26,  4.20s/it]\u001b[A\n",
      "train batches:  24%|██▍       | 11/45 [00:46<02:20,  4.13s/it]\u001b[A\n",
      "train batches:  27%|██▋       | 12/45 [00:51<02:19,  4.23s/it]\u001b[A\n",
      "train batches:  29%|██▉       | 13/45 [00:55<02:13,  4.16s/it]\u001b[A\n",
      "train batches:  31%|███       | 14/45 [00:59<02:07,  4.10s/it]\u001b[A\n",
      "train batches:  33%|███▎      | 15/45 [01:02<02:01,  4.05s/it]\u001b[A\n",
      "train batches:  36%|███▌      | 16/45 [01:07<02:04,  4.28s/it]\u001b[A\n",
      "train batches:  38%|███▊      | 17/45 [01:12<02:03,  4.41s/it]\u001b[A\n",
      "train batches:  40%|████      | 18/45 [01:16<01:55,  4.28s/it]\u001b[A\n",
      "train batches:  42%|████▏     | 19/45 [01:20<01:48,  4.18s/it]\u001b[A\n",
      "train batches:  44%|████▍     | 20/45 [01:25<01:54,  4.56s/it]\u001b[A\n",
      "train batches:  47%|████▋     | 21/45 [01:29<01:46,  4.43s/it]\u001b[A\n",
      "train batches:  49%|████▉     | 22/45 [01:33<01:38,  4.27s/it]\u001b[A\n",
      "train batches:  51%|█████     | 23/45 [01:38<01:34,  4.31s/it]\u001b[A\n",
      "train batches:  53%|█████▎    | 24/45 [01:42<01:29,  4.25s/it]\u001b[A\n",
      "train batches:  56%|█████▌    | 25/45 [01:46<01:23,  4.18s/it]\u001b[A\n",
      "train batches:  58%|█████▊    | 26/45 [01:50<01:18,  4.13s/it]\u001b[A\n",
      "train batches:  60%|██████    | 27/45 [01:55<01:17,  4.28s/it]\u001b[A\n",
      "train batches:  62%|██████▏   | 28/45 [01:59<01:11,  4.22s/it]\u001b[A\n",
      "train batches:  64%|██████▍   | 29/45 [02:03<01:06,  4.13s/it]\u001b[A\n",
      "train batches:  67%|██████▋   | 30/45 [02:06<01:00,  4.06s/it]\u001b[A\n",
      "train batches:  69%|██████▉   | 31/45 [02:11<00:59,  4.22s/it]\u001b[A\n",
      "train batches:  71%|███████   | 32/45 [02:15<00:55,  4.25s/it]\u001b[A\n",
      "train batches:  73%|███████▎  | 33/45 [02:19<00:50,  4.20s/it]\u001b[A\n",
      "train batches:  76%|███████▌  | 34/45 [02:23<00:45,  4.15s/it]\u001b[A\n",
      "train batches:  78%|███████▊  | 35/45 [02:28<00:42,  4.28s/it]\u001b[A\n",
      "train batches:  80%|████████  | 36/45 [02:32<00:38,  4.25s/it]\u001b[A\n",
      "train batches:  82%|████████▏ | 37/45 [02:36<00:33,  4.15s/it]\u001b[A\n",
      "train batches:  84%|████████▍ | 38/45 [02:40<00:28,  4.09s/it]\u001b[A\n",
      "train batches:  87%|████████▋ | 39/45 [02:44<00:25,  4.17s/it]\u001b[A\n",
      "train batches:  89%|████████▉ | 40/45 [02:49<00:20,  4.19s/it]\u001b[A\n",
      "train batches:  91%|█████████ | 41/45 [02:53<00:16,  4.15s/it]\u001b[A\n",
      "train batches:  93%|█████████▎| 42/45 [02:57<00:12,  4.12s/it]\u001b[A\n",
      "train batches:  96%|█████████▌| 43/45 [03:01<00:08,  4.16s/it]\u001b[A\n",
      "train batches:  98%|█████████▊| 44/45 [03:05<00:04,  4.11s/it]\u001b[A\n",
      "train batches: 100%|██████████| 45/45 [03:08<00:00,  4.20s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "training epochs:  10%|█         | 1/10 [04:05<36:51, 245.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss:  4.845042165120443\n",
      "Epoch accuracy:  0.5860627177700348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "train batches:   0%|          | 0/45 [00:00<?, ?it/s]\u001b[A\n",
      "train batches:   2%|▏         | 1/45 [00:04<03:02,  4.16s/it]\u001b[A\n",
      "train batches:   4%|▍         | 2/45 [00:10<03:53,  5.42s/it]\u001b[A\n",
      "training epochs:  10%|█         | 1/10 [04:16<38:29, 256.56s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8468/265757723.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\models\\resnet.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 283\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\models\\resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    271\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 273\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    274\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\models\\resnet.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[0midentity\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    445\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 447\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    448\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    441\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m--> 443\u001b[1;33m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[0;32m    444\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[0;32m    445\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "for epoch in tqdm(range(num_epochs), desc='training epochs'):\n",
    "    # set the model to train mode\n",
    "    model.train()\n",
    "    train_running_loss = 0.0\n",
    "    train_running_correct = 0\n",
    "    counter = 0\n",
    "    \n",
    "    for images, labels in tqdm(train_loader, desc='train batches'):\n",
    "        counter += 1\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        preds = model(images).to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "    # evaluate at the end of each epoch\n",
    "    # Mike TODO\n",
    "#         train_running_loss += loss.item()\n",
    "        \n",
    "#         preds = torch.max(outputs,1)\n",
    "#         train_running_correct += preds.sum().item()\n",
    "        \n",
    "#         optimizer.step()\n",
    "    \n",
    "    \n",
    "#     epoch_loss = train_running_loss / counter\n",
    "#     epoch_acc = 100. * (train_running_correct / len(train_loader.dataset))\n",
    "\n",
    "    print(\"Epoch\", epoch + 1)\n",
    "    epoch_acc, epoch_loss = evaluate_model(model, train_loader)\n",
    "    print(\"Epoch loss: \", epoch_loss)\n",
    "    print(\"Epoch accuracy: \", epoch_acc)\n",
    "\n",
    "# save the model checkpoint after training\n",
    "# in case we want to use it again for class demo\n",
    "output_dir = 'output'\n",
    "try:\n",
    "    os.mkdir(output_dir)\n",
    "except:\n",
    "    # we don't care if it already exists... move on\n",
    "    pass\n",
    "\n",
    "model.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6f1681-896c-4ec1-8f1c-f8ee208384a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
